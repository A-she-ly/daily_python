{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ed847-6a42-4a73-8334-50aca4453fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c5046-6b36-4555-bf7a-40814fc32f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入DF、文件名称，生成EXCEL表格\n",
    "def generate_excel(df, f_name):\n",
    "    if (df.shape[0] == 0):\n",
    "        print ('没有数据产出。')\n",
    "    else:\n",
    "        if os.path.exists(f_name):\n",
    "            os.remove(f_name)\n",
    "        df.to_excel(f_name, index=False)\n",
    "        print(f_name, '文件已生成。')\n",
    "\n",
    "#根据DF的某个列生成文件夹\n",
    "def generate_folder(df, field):\n",
    "    for f in list(df[field].unique()):\n",
    "        print (f)\n",
    "        if os.path.exists(f):\n",
    "#             os.remove(f) #会报错：remove用于删除文件\n",
    "            os.rmdir(f) #rmdir用于删除文件夹\n",
    "        os.mkdir(f)\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "#将文件列表解析成一个DF\n",
    "def concat_files(files):\n",
    "    df = pd.DataFrame()\n",
    "    for f in files:\n",
    "        if re.search('.xlsx', f) != None:\n",
    "            data = pd.read_excel(f)\n",
    "        if re.search('.csv', f) != None:\n",
    "            data = pd.read_csv(f)\n",
    "        df = pd.concat([df, data], axis=0, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "#获得【标准】网址名\n",
    "def get_clean_url(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(\"\\s\", \"\", s)\n",
    "    s = re.sub(\"/\", \"\", s)\n",
    "    match = re.search('www.', s)\n",
    "    site = s\n",
    "    if match != None:\n",
    "        start = match.span()[1]\n",
    "        site = s[start:]\n",
    "    return site\n",
    "\n",
    "#获得已经关停的商户\n",
    "def get_down_mers():\n",
    "    down_mers = pd.read_excel('资料汇总.xlsx', sheet_name='关停商户')\n",
    "    down_mers = down_mers.applymap(str)\n",
    "    down_mers['商户号'] = down_mers['商户号'].map(lambda x: x.replace('.0', ''))\n",
    "    return down_mers\n",
    "\n",
    "#获得已经关停的网站\n",
    "def get_down_urls():\n",
    "    down_urls = pd.read_excel('资料汇总.xlsx', sheet_name='关停网站')\n",
    "    down_urls = down_urls.applymap(str)\n",
    "    down_urls['商户号'] = down_urls['商户号'].map(lambda x: x.replace('.0', ''))\n",
    "    return down_urls\n",
    "\n",
    "#获得商户详情，如AM/BD\n",
    "def get_mer_info():\n",
    "    mer_info = pd.read_excel('资料汇总.xlsx', sheet_name='AM分配')\n",
    "    mer_info = mer_info.applymap(str)\n",
    "    mer_info['商户号'] = mer_info['商户号'].map(lambda x: x.replace('.0', ''))\n",
    "    return mer_info\n",
    "\n",
    "#查看商户是否分配AM\n",
    "def check_am(df):\n",
    "    no_ams = df[df['AM'].isnull()]\n",
    "    nan_ams = df[df['AM']=='nan']\n",
    "    if((no_ams.shape[0] != 0) or (nan_ams.shape[0] !=0)):\n",
    "        print('如下商户还未分配AM：')\n",
    "        for mer in list(no_ams['商户号'].unique()):\n",
    "            print (mer)\n",
    "        for mer in list(nan_ams['商户号'].unique()):\n",
    "            print (mer)\n",
    "    else:\n",
    "        print('AM都已分配妥当。')\n",
    "\n",
    "#循环输出某一列的唯一值，如输出所有的AM/BD/商户号等\n",
    "def iterate_col(df, col):\n",
    "    items = df[col].unique()\n",
    "    for i in list(items):\n",
    "        print('      ',i)\n",
    "\n",
    "#根据某一列的唯一值分割DF,并返回DF列表\n",
    "def split_dfs(df, col):\n",
    "    dfs = []\n",
    "    items = df[col].unique()\n",
    "    for i in list(items):\n",
    "#         print(i)\n",
    "        sub_df = df[df[col] == i]\n",
    "        if (sub_df.shape[0] != 0):\n",
    "            dfs.append(sub_df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f0f0d-c588-4b00-8a80-2fe61676bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网站复审 2022, 2, 17 Thur\n",
    "# 0）去重\n",
    "# 1)删除停用的商户\n",
    "# 2）商户停用的网站\n",
    "# 3）匹配AM/BD\n",
    "sites = pd.read_excel('网址匹配商户号20200207.xlsx')\n",
    "# 0）去重\n",
    "sites = sites.applymap(str)\n",
    "sites['URL'] = sites['URL'].map(lambda x: x.lower())\n",
    "sites.drop_duplicates('URL', inplace=True)\n",
    "print('去重后：', sites.shape[0])\n",
    "# sites[sites['URL'].duplicated(keep=False)].sort_values('URL')\n",
    "\n",
    "# 1)删除停用的商户\n",
    "down_mers = get_down_mers()\n",
    "sites[sites['商户号'].isin(set(down_mers['商户号']))] #查看是否存在关停商户\n",
    "sites.drop(sites[sites['商户号'].isin(set(down_mers['商户号']))].index, inplace=True)\n",
    "print('删除关停商户相关的记录后：', sites.shape[0])\n",
    "\n",
    "# 2）商户停用的网站\n",
    "down_urls = get_down_urls()\n",
    "sites.drop(sites[sites['URL'].isin(set(down_urls['URL']))].index, inplace=True)\n",
    "print('删除关停网站相关的记录后：', sites.shape[0])\n",
    "\n",
    "# 3）匹配AM/BD\n",
    "mer_info = get_mer_info()\n",
    "urls = sites.merge(mer_info[['AM', 'BD', '商户号']], on='商户号', how='left')\n",
    "check_am(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6adc060-bd19-42e5-b1dd-794ccb50e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = urls.head(20)\n",
    "urls_4am = split_dfs(sample, 'AM')\n",
    "for df in urls_4am:\n",
    "    am = df.AM.unique()\n",
    "    print ('To', am[0])\n",
    "    ms = split_dfs(df, '商户号')\n",
    "    for m in ms:\n",
    "        m_no = m['商户号'].unique()\n",
    "        print('   To', m_no[0])\n",
    "        iterate_col(m, 'URL' )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0c477-14d3-4d74-9a00-b4af478ea9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
