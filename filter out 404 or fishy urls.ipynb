{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c79ae7df-c8dd-4561-9460-61f9e27f5545",
   "metadata": {},
   "source": [
    "# Codes' functionality:\n",
    "## Single out websites that \n",
    "* can not be opened(return 404) \n",
    "* or throw exception when requests.get(url)\n",
    "#### Python get:\n",
    "* try...except...finally syntax\n",
    "* construct DataFrame\n",
    "\n",
    "### Nice coding habits:\n",
    "* truncate a small amount of data to process during testing stage,\n",
    "** such as: urls = urls.loc[10:20] allows only 10 entries to be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71a5bfac-8705-4305-aea1-c5dae940b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import webbrowser\n",
    "from datetime import date\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1afbecb-4de5-43a8-aa1e-0c23f1e2edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_excel(df, f_name):\n",
    "    if (df.shape[0] == 0):\n",
    "        print ('没有数据产出。')\n",
    "    else:\n",
    "        if os.path.exists(f_name):\n",
    "            os.remove(f_name)\n",
    "        df.to_excel(f_name, index=False)\n",
    "        print(f_name, '文件已生成。')\n",
    "#获得商户详情，如AM/BD\n",
    "def get_mer_info():\n",
    "    mer_info = pd.read_excel('资料汇总.xlsx', sheet_name='AM分配')\n",
    "    mer_info = mer_info.applymap(str)\n",
    "    mer_info['商户号'] = mer_info['商户号'].map(lambda x: x.replace('.0', ''))\n",
    "    return mer_info\n",
    "#获得已经关停的网站\n",
    "def get_down_urls():\n",
    "    down_urls = pd.read_excel('资料汇总.xlsx', sheet_name='关停网站')\n",
    "    down_urls = down_urls.applymap(str)\n",
    "    down_urls['商户号'] = down_urls['商户号'].map(lambda x: x.replace('.0', ''))\n",
    "    return down_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff1dec9f-faee-4a5b-bd06-24da8e8b61d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始网址数量： 357\n",
      "删除重复网址： 351\n",
      "删除关停网址： 333\n",
      "待查看的URL数量 322\n",
      "待查看的404网站数量： 118\n",
      "过关的网站数量： 204\n",
      "2022-02-18待查网站.xlsx 文件已生成。\n"
     ]
    }
   ],
   "source": [
    "#收集打不开的URL\n",
    "urls = pd.read_excel('top4-11.xlsx')\n",
    "urls = urls.applymap(str)\n",
    "print('初始网址数量：', urls.shape[0])\n",
    "urls.drop_duplicates('TRADEURL', inplace=True)\n",
    "print('删除重复网址：', urls.shape[0])\n",
    "urls.drop(urls[urls['TRADEURL'] == 'Total'].index, inplace=True)\n",
    "down_urls = get_down_urls()\n",
    "urls.drop(urls[urls['TRADEURL'].isin(down_urls['URL'])].index, inplace=True)\n",
    "print('删除关停网址：', urls.shape[0])\n",
    "\n",
    "urls.TRADEURL = urls.TRADEURL.map(lambda x: x.replace('www.', ''))\n",
    "# urls.head(2)\n",
    "\n",
    "# truncate a small amount of data to process during testing stage\n",
    "# urls = urls.loc[10:20]\n",
    "#判断打不开的\n",
    "site_size = len(urls['TRADEURL'].unique())\n",
    "print ('待查看的URL数量', site_size)\n",
    "check_list = 0\n",
    "url_404 = []\n",
    "for i, link in enumerate(list(urls.TRADEURL.unique())):\n",
    "#     print(link)\n",
    "    mer_no = urls[urls.TRADEURL == link]['MER_NO'].unique()[0]\n",
    "    try:\n",
    "        resp = requests.get('https://www.' + link)\n",
    "        if (resp.status_code == 404):\n",
    "    # #         webbrowser.open('http://www.' + link)     \n",
    "            record = pd.DataFrame({'商户号': [mer_no], 'URL': [link], '404': '打不开'})\n",
    "            url_404.append(record)\n",
    "            check_list = check_list + 1  \n",
    "    except:\n",
    "        record = pd.DataFrame({'商户号': [mer_no], 'URL': [link], '404': '出错了'})\n",
    "        url_404.append(record)\n",
    "        check_list = check_list + 1\n",
    "#         webbrowser.open('http://www.' + link)\n",
    "            \n",
    "df_404 = pd.concat(url_404, axis=0, ignore_index=True )\n",
    "print('待查看的404网站数量：', check_list)\n",
    "print('过关的网站数量：', site_size - check_list)\n",
    "mers = get_mer_info()\n",
    "df_404 = df_404.applymap(str)\n",
    "df = df_404.merge(mers[['AM', '商户号']], on='商户号', how='left')\n",
    "f_name = str(date.today()) + '待查网站.xlsx'\n",
    "generate_excel(df, f_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
